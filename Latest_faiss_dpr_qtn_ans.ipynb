{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFgPbgJB/sM8ytG0/MSlQC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chirag900/Amazon-Fine-Food-Reviews/blob/main/Latest_faiss_dpr_qtn_ans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdQVtmXODPxn",
        "outputId": "e9c825c6-a0e8-4d49-b9e2-85158b4f7355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "# Load the DPR context and question encoder models and tokenizers\n",
        "ctx_model_name_or_path = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
        "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(ctx_model_name_or_path)\n",
        "ctx_model = DPRContextEncoder.from_pretrained(ctx_model_name_or_path)\n",
        "\n",
        "q_model_name_or_path = \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(q_model_name_or_path)\n",
        "q_model = DPRQuestionEncoder.from_pretrained(q_model_name_or_path)\n",
        "\n",
        "# Generate embeddings for a set of contexts and a query\n",
        "contexts = [\"it is raining because this is rainy season \", \"Context 2\", \"Context 3\"]\n",
        "context_inputs = ctx_tokenizer(contexts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "context_embeddings = ctx_model(**context_inputs).pooler_output.detach().numpy()\n",
        "\n",
        "query = \"why is it raining?\"\n",
        "query_input = q_tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "query_embedding = q_model(**query_input).pooler_output.detach().numpy()\n",
        "\n",
        "# Configure and train the Faiss indexer\n",
        "index = faiss.IndexFlatIP(context_embeddings.shape[1])\n",
        "index.add(context_embeddings)\n",
        "\n",
        "# Perform a query to retrieve the most similar contexts\n",
        "k = 2  # Number of most similar contexts to retrieve\n",
        "distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "# Print the retrieved contexts and their distances\n",
        "for i, idx in enumerate(indices[0]):\n",
        "    print(f\"{i+1}. Context {idx+1} (distance: {distances[0][i]}) - {contexts[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLeNvMd1EkCR",
        "outputId": "79bf187b-a49b-40f6-9667-3325283290a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Context 1 (distance: 69.29586029052734) - it is raining because this is rainy season \n",
            "2. Context 3 (distance: 46.292049407958984) - Context 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDIEUl_NDXZX",
        "outputId": "528dd0d2-053a-4b69-b87e-0097128de8f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
        "\n",
        "# Load the DPR context encoder model and tokenizer\n",
        "model_name_or_path = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
        "tokenizer = DPRContextEncoderTokenizer.from_pretrained(model_name_or_path)\n",
        "model = DPRContextEncoder.from_pretrained(model_name_or_path)\n",
        "\n",
        "# Generate embeddings for a set of contexts\n",
        "contexts = ['name of the company is mercede',\"Context 2\", \"Context 3\"]\n",
        "context_inputs = tokenizer(contexts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "context_embeddings = model(**context_inputs).pooler_output.detach().numpy()\n",
        "\n",
        "# Configure and train the Faiss indexer\n",
        "index = faiss.IndexFlatIP(context_embeddings.shape[1])\n",
        "index.add(context_embeddings)\n",
        "\n",
        "# Perform a query to retrieve the most similar contexts\n",
        "query = \"what is the name of company\"\n",
        "query_input = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "query_embedding = model(**query_input).pooler_output.detach().numpy()\n",
        "\n",
        "k = 5  # Number of most similar contexts to retrieve\n",
        "distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "# Print the retrieved contexts and their distances\n",
        "for i, idx in enumerate(indices[0]):\n",
        "    print(f\"{i+1}. Context {idx+1} (distance: {distances[0][i]}) - {contexts[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbyOr-1qDViN",
        "outputId": "bbf562ea-d17e-4292-e42e-2fab8e393a8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Context 1 (distance: 108.74156951904297) - name of the company is mercede\n",
            "2. Context 3 (distance: 78.91181945800781) - Context 3\n",
            "3. Context 2 (distance: 78.20260620117188) - Context 2\n",
            "4. Context 0 (distance: -3.4028234663852886e+38) - Context 3\n",
            "5. Context 0 (distance: -3.4028234663852886e+38) - Context 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer, pipeline\n",
        "\n",
        "# Load the DPR context and question encoder models and tokenizers\n",
        "ctx_model_name_or_path = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
        "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(ctx_model_name_or_path)\n",
        "ctx_model = DPRContextEncoder.from_pretrained(ctx_model_name_or_path)\n",
        "\n",
        "q_model_name_or_path = \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(q_model_name_or_path)\n",
        "q_model = DPRQuestionEncoder.from_pretrained(q_model_name_or_path)\n",
        "\n",
        "# Generate embeddings for a set of contexts and a query\n",
        "contexts = [\"the company for which Amit works is Robert Bosch\", \"Context 2\", \"Context 3\"]\n",
        "context_inputs = ctx_tokenizer(contexts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "context_embeddings = ctx_model(**context_inputs).pooler_output.detach().numpy()\n",
        "\n",
        "query = \"in which company Amit works?\"\n",
        "query_input = q_tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "query_embedding = q_model(**query_input).pooler_output.detach().numpy()\n",
        "\n",
        "# Configure and train the Faiss indexer\n",
        "index = faiss.IndexFlatIP(context_embeddings.shape[1])\n",
        "index.add(context_embeddings)\n",
        "\n",
        "# Perform a query to retrieve the most similar contexts\n",
        "k = 5  # Number of most similar contexts to retrieve\n",
        "distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "# Extract the relevant passages or sentences that answer the question\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "for i, idx in enumerate(indices[0]):\n",
        "    context = contexts[idx]\n",
        "    answer = qa_pipeline(question=query, context=context)\n",
        "    print(f\"{i+1}. Context {idx+1} (distance: {distances[0][i]}) - {context}:\")\n",
        "    print(answer[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtVUtFNjHAxN",
        "outputId": "e05017d4-e3ea-41e9-fc38-490072444806"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Context 1 (distance: 70.81763458251953) - the company for which Amit works is Robert Bosch:\n",
            "Robert Bosch\n",
            "2. Context 3 (distance: 51.510154724121094) - Context 3:\n",
            "Context 3\n",
            "3. Context 2 (distance: 49.555992126464844) - Context 2:\n",
            "Context 2\n",
            "4. Context 0 (distance: -3.4028234663852886e+38) - Context 3:\n",
            "Context 3\n",
            "5. Context 0 (distance: -3.4028234663852886e+38) - Context 3:\n",
            "Context 3\n"
          ]
        }
      ]
    }
  ]
}